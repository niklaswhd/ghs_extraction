{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43b7fb-b1e5-4771-850b-71ef4e28be47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script that uses an excel table of CAS numbers of a couple of chemical elements as an input\n",
    "# the table will be selected with tkinter\n",
    "# afterwards the pubchem (a chemical database) will be searched for every element and put in a new column\n",
    "# finally it extracts the source URL of the GHS classification of the European Chemical Agency (ECHA) of each element and puts the URL in a new column\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import tkinter\n",
    "from tkinter import *\n",
    "from tkinter import filedialog\n",
    "import os\n",
    "from thermo.chemical import Chemical\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# open dialog to load the excel spreadsheet\n",
    "root = tkinter.Tk()\n",
    "request_load_file = filedialog.askopenfile(initialdir=os.getcwd(), filetypes=[('Excel Files', '*.xlsx'), ('CSV Files', '*.csv')])\n",
    "if request_load_file:\n",
    "    filepath = os.path.abspath(request_load_file.name)\n",
    "root.destroy()\n",
    "\n",
    "if filepath.endswith('.xlsx'):\n",
    "    df_inventory = pd.read_excel(filepath)\n",
    "elif filepath.endswith('.csv'):\n",
    "    df_inventory = pd.read_csv(filepath)\n",
    "\n",
    "# create new columns\n",
    "df_inventory['PubChem ID'] = np.nan\n",
    "df_inventory['ECHA URL'] = np.nan\n",
    "df_inventory['GHS'] = np.nan\n",
    "df_inventory['H Statements'] = np.nan\n",
    "df_inventory['Signal'] = np.nan\n",
    "\n",
    "\n",
    "# resolve PubChem IDs from CAS numbers\n",
    "for i in df_inventory['CAS']:\n",
    "    try:\n",
    "        chem = Chemical(f'{i}')\n",
    "        df_inventory.loc[df_inventory['CAS'] == i, 'PubChem ID'] = chem.PubChem\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Progress Part One: extract ECHA URL from PubChem data\n",
    "pubchem_ids = set(df_inventory['PubChem ID'].dropna())\n",
    "\n",
    "for chem_id in tqdm(pubchem_ids, desc=\"Progress Part One: Extracting ECHA URLs\"):\n",
    "    try:\n",
    "        result = requests.get(\n",
    "            f'https://pubchem.ncbi.nlm.nih.gov/rest/pug_view/data/compound/{int(chem_id)}/JSON/?response_type=display&heading=GHS%20Classification'\n",
    "        )\n",
    "        data = result.json()\n",
    "        sections = data['Record']['Section']\n",
    "\n",
    "        def find_echa_url(sections):\n",
    "            for section in sections:\n",
    "                if section.get('TOCHeading') == 'GHS Classification':\n",
    "                    for info in section.get('Information', []):\n",
    "                        if info.get('Name') == 'ECHA C&L Notifications Summary':\n",
    "                            if 'Value' in info:\n",
    "                                for item in info['Value'].get('StringWithMarkup', []):\n",
    "                                    for markup in item.get('Markup', []):\n",
    "                                        if 'URL' in markup:\n",
    "                                            return markup['URL']\n",
    "                if 'Section' in section:\n",
    "                    url = find_echa_url(section['Section'])\n",
    "                    if url:\n",
    "                        return url\n",
    "            return None\n",
    "\n",
    "        echa_url = find_echa_url(sections)\n",
    "        if echa_url:\n",
    "            df_inventory.loc[df_inventory['PubChem ID'] == chem_id, 'ECHA URL'] = echa_url\n",
    "\n",
    "    except Exception:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95bdfa-c6a0-4ad6-ba99-84e6b0bf933e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second part of the script\n",
    "# visits every ECHA source URL and extracts the information of the summary table of the GHS classification (always named \"table 3\")\n",
    "# extracts GHS pictograms classification (e. g. GHS01 explosive) and H statements (e. g. H360\tMay damage fertility or the unborn child) and signal word (danger or warning)\n",
    "# if summary table 3 does not exist, skips the element\n",
    "\n",
    "def retrieve_echa_data(df):\n",
    "    #session setup with user-agent setting\n",
    "    session = requests.Session()\n",
    "    session.headers.update({\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "                      \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "                      \"Chrome/122.0.0.0 Safari/537.36\",\n",
    "        \"Referer\": \"https://www.google.com\"\n",
    "    })\n",
    "    \n",
    "    time.sleep(3)\n",
    "\n",
    "    urls_to_process = df[df['ECHA URL'].notna()]\n",
    "\n",
    "    #main loop with tqdm to track progress\n",
    "    for idx, row in tqdm(urls_to_process.iterrows(), total=len(urls_to_process), desc=\"Retrieving ECHA data\"):\n",
    "        url = row['ECHA URL']\n",
    "        try:\n",
    "            response = session.get(url)\n",
    "            if response.status_code != 200:\n",
    "                print(f\"Failed to fetch the page at {url}. Status code: {response.status_code}\")\n",
    "                continue\n",
    "\n",
    "            #html parsing of website\n",
    "            soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "            #search for table 3\n",
    "            table_heading = soup.find('span', string=re.compile(r'CLP Classification \\(Table 3\\)'))\n",
    "            if not table_heading:\n",
    "                print(f\"Table 3 not found for {url}\")\n",
    "                continue\n",
    "\n",
    "            table = table_heading.find_next('table')\n",
    "            if not table:\n",
    "                print(f\"Classification table not found for {url}\")\n",
    "                continue\n",
    "\n",
    "            h_statements = set()\n",
    "            ghs_codes = set()\n",
    "            signal_word = None\n",
    "\n",
    "            #extract H statements and signal words\n",
    "            for tr in table.find_all('tr', class_='results-row'):\n",
    "                tds = tr.find_all('td')\n",
    "                for td in tds:\n",
    "                    h_spans = td.find_all('span', class_='CLInventoryHelpCursor')\n",
    "                    for span in h_spans:\n",
    "                        text = span.get_text(strip=True)\n",
    "                        if re.match(r'H\\d{3}', text):\n",
    "                            h_statements.add(text)\n",
    "\n",
    "                    text_content = td.get_text(\" \", strip=True)\n",
    "                    ghs_codes.update(re.findall(r'GHS\\d{2}', text_content))\n",
    "                    if 'Dgr' in text_content:\n",
    "                        signal_word = 'Danger'\n",
    "                    elif 'Wng' in text_content:\n",
    "                        signal_word = 'Warning'\n",
    "\n",
    "            # Save extracted data\n",
    "            df.at[idx, 'H Statements'] = ', '.join(sorted(h_statements)) if h_statements else None\n",
    "            df.at[idx, 'GHS'] = ', '.join(sorted(ghs_codes)) if ghs_codes else None\n",
    "            df.at[idx, 'Signal'] = signal_word\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error retrieving data for URL {url}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "retrieve_echa_data (df_inventory)\n",
    "\n",
    "# save output\n",
    "df_inventory.to_excel(filepath[:filepath.rfind('.')] + '_echa_dat.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
